{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0666a2be",
   "metadata": {},
   "source": [
    "\n",
    "In order to obtain accurate results, datasets' labels must be remapped for anomaly purposes where the OoD class is remapped to (1) and the in-distribution (ID) classes are remapped to (0). \n",
    "The different benchmarks have different labelling sequences, hence, the unique labels of each dataset must be known before deciding the remapping logic. Below is the implementation of a code that prints out the unique labels found in each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab1446bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images. Analyzing unique pixel values...\n",
      "------------------------------\n",
      "Unique Label Values found in directory: \n",
      "[0, 1, 255]\n",
      "------------------------------\n",
      "\n",
      "Common Mapping Guide for RoadObstacle21/RoadAnomaly21:\n",
      " - 0: Usually In-Distribution (Road/Background)\n",
      " - 1 or 2: Usually Anomaly/Obstacle\n",
      " - 255: Usually Void/Ignore (Not evaluated)\n"
     ]
    }
   ],
   "source": [
    "!python eval/printlabels.py \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\labels_masks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb686188",
   "metadata": {},
   "source": [
    "evalAnomalyERFNet.py is the code to run all evaluations done on ERFNet. The code is conclusive of all tasks (all post-hoc).\n",
    "If there is a need to save logits, pass a new argument '--save_logits' while using 'MSP' as the post-hoc method.\n",
    "For using temperature scaling with MSP, switch to method: 'MSP-T' and add the argument '--tempScale'  (e.g --tempScale 1.1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "752db33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization results will be saved to: c:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eval\\vis_erfnet\\MSP\n",
      "Loading model: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject/eval/erfnet.py\n",
      "Loading weights: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject/trained_models/erfnet_pretrained.pth\n",
      "Model and weights LOADED successfully\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\0.png\n",
      "Saved visualization for 0\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\1.png\n",
      "Saved visualization for 1\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\2.png\n",
      "Saved visualization for 2\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\3.png\n",
      "Saved visualization for 3\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\4.png\n",
      "Saved visualization for 4\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\5.png\n",
      "Saved visualization for 5\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\6.png\n",
      "Saved visualization for 6\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\7.png\n",
      "Saved visualization for 7\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\8.png\n",
      "Saved visualization for 8\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\9.png\n",
      "Saved visualization for 9\n",
      "Number of processed images:  10\n",
      "val_label size:  5060302\n",
      "val_out size:  5060302\n",
      "unique labels:  [0. 1.]\n",
      "AUPRC score: 29.085011029970442\n",
      "FPR@TPR95: 62.55343909446874\n"
     ]
    }
   ],
   "source": [
    "!python eval/evalAnomalyERFNet.py --input \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\\*.png\" --method \"MSP\" --datadir \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\" --tempScale 0.5 --logits_dir \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Saved_Logits_MSP\\logits_RoadAnomaly21\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a2628",
   "metadata": {},
   "source": [
    "eval_iouERFNet computes the mIoU and IoU per class (ID or OoD)\n",
    "The code binarizes the outputs of the model in order to adapt to anomaly segmentation requirements. For that purpose a new argument is used '--threshold' which defines the threshold score for the criteria of binarization. The threshold's value is to be tuned for the value that yields best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2c85c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject/eval/erfnet.py\n",
      "Loading weights: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject/trained_models/erfnet_pretrained.pth\n",
      "Model and weights LOADED successfully\n",
      "C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\FS_LostFound_full\\images C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\FS_LostFound_full\\labels_masks\n",
      "Loaded 100 images and 100 masks from C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\FS_LostFound_full\n",
      "0 0.png\n",
      "1 1.png\n",
      "2 10.png\n",
      "3 11.png\n",
      "4 12.png\n",
      "5 13.png\n",
      "6 14.png\n",
      "7 15.png\n",
      "8 16.png\n",
      "9 17.png\n",
      "10 18.png\n",
      "11 19.png\n",
      "12 2.png\n",
      "13 20.png\n",
      "14 21.png\n",
      "15 22.png\n",
      "16 23.png\n",
      "17 24.png\n",
      "18 25.png\n",
      "19 26.png\n",
      "20 27.png\n",
      "21 28.png\n",
      "22 29.png\n",
      "23 3.png\n",
      "24 30.png\n",
      "25 31.png\n",
      "26 32.png\n",
      "27 33.png\n",
      "28 34.png\n",
      "29 35.png\n",
      "30 36.png\n",
      "31 37.png\n",
      "32 38.png\n",
      "33 39.png\n",
      "34 4.png\n",
      "35 40.png\n",
      "36 41.png\n",
      "37 42.png\n",
      "38 43.png\n",
      "39 44.png\n",
      "40 45.png\n",
      "41 46.png\n",
      "42 47.png\n",
      "43 48.png\n",
      "44 49.png\n",
      "45 5.png\n",
      "46 50.png\n",
      "47 51.png\n",
      "48 52.png\n",
      "49 53.png\n",
      "50 54.png\n",
      "51 55.png\n",
      "52 56.png\n",
      "53 57.png\n",
      "54 58.png\n",
      "55 59.png\n",
      "56 6.png\n",
      "57 60.png\n",
      "58 61.png\n",
      "59 62.png\n",
      "60 63.png\n",
      "61 64.png\n",
      "62 65.png\n",
      "63 66.png\n",
      "64 67.png\n",
      "65 68.png\n",
      "66 69.png\n",
      "67 7.png\n",
      "68 70.png\n",
      "69 71.png\n",
      "70 72.png\n",
      "71 73.png\n",
      "72 74.png\n",
      "73 75.png\n",
      "74 76.png\n",
      "75 77.png\n",
      "76 78.png\n",
      "77 79.png\n",
      "78 8.png\n",
      "79 80.png\n",
      "80 81.png\n",
      "81 82.png\n",
      "82 83.png\n",
      "83 84.png\n",
      "84 85.png\n",
      "85 86.png\n",
      "86 87.png\n",
      "87 88.png\n",
      "88 89.png\n",
      "89 9.png\n",
      "90 90.png\n",
      "91 91.png\n",
      "92 92.png\n",
      "93 93.png\n",
      "94 94.png\n",
      "95 95.png\n",
      "96 96.png\n",
      "97 97.png\n",
      "98 98.png\n",
      "99 99.png\n",
      "---------------------------------------\n",
      "Results for Method: MaxE (Threshold: 0.5)\n",
      "Took  18.71115756034851 seconds\n",
      "=======================================\n",
      "Per-Class IoU:\n",
      "\u001b[36;1m79.64\u001b[0m Normal (In-Distribution)\n",
      "\u001b[33;1m20.97\u001b[0m Anomaly (Out-of-Distribution)\n",
      "=======================================\n",
      "MEAN IoU:  \u001b[34;1m50.31\u001b[0m %\n"
     ]
    }
   ],
   "source": [
    "!python eval/eval_iouERFNet.py --datadir \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\FS_LostFound_full\" --method \"MaxE\" --threshold 0.5 --tempScale 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4301fb",
   "metadata": {},
   "source": [
    "Install dependencies for adapting the eval code for EoMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install timm transformers\n",
    "!pip3 install omegaconf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0eaac4",
   "metadata": {},
   "source": [
    "evalAnomalyEoMT.py is the code to run all evaluations done on EoMT. The code is conclusive of all tasks (all post-hoc).\n",
    "If there is a need to save logits, pass a new argument '--save_logits' while using 'MSP' as the post-hoc method.\n",
    "For using temperature scaling with MSP, switch to method: 'MSP-T' and add the argument '--tempScale'  (e.g --tempScale 1.1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba4c185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: c:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\n",
      "Added to Path: c:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt\n",
      "Scanning images in: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\\images\n",
      "Found 10 images.\n",
      "Loading configuration from C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt\\configs\\dinov2\\cityscapes\\semantic\\eomt_base_640.yaml...\n",
      "Building EoMT network for resolution (640, 1280)...\n",
      "Using local checkpoint: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt_checkpoints\\epoch_106-step_19902_eomt.ckpt\n",
      "Loading state dict...\n",
      "Resizing pos_embed: ckpt torch.Size([1, 4096, 768]) -> model torch.Size([1, 3200, 768])\n",
      "Weights Loaded. Missing: 0, Unexpected: 1\n",
      "Processing 0/10: 0.png\n",
      "\n",
      "Calculating Metrics...\n",
      "Method: MaxEntropy\n",
      "AUPRC: 63.4725\n",
      "FPR@95: 32.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eval\\evalAnomalyEoMT.py:294: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(gt_mask, cmap=cm.get_cmap(\"binary\").reversed())\n"
     ]
    }
   ],
   "source": [
    "!python eval/evalAnomalyEoMT.py --input \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly21\" --dataset RoadAnomaly21 --config \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt\\configs\\dinov2\\cityscapes\\semantic\\eomt_base_640.yaml\" --ckpt \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt_checkpoints\\epoch_106-step_19902_eomt.ckpt\" --method MaxEntropy --save --tempScale 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa2eb1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning images in: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly\\images\n",
      "Found 60 images.\n",
      "Loading configuration from C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt\\configs\\dinov2\\cityscapes\\semantic\\eomt_base_640.yaml...\n",
      "Building EoMT Network for resolution (640, 1280)...\n",
      "Using local checkpoint: C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt_checkpoints\\epoch_106-step_19902_eomt.ckpt\n",
      "Loading state dict...\n",
      "Resizing pos_embed: ckpt torch.Size([1, 4096, 768]) -> model torch.Size([1, 3200, 768])\n",
      "Weights Loaded.\n",
      "Processing 0/60: 0.jpg\n",
      "Processing 10/60: 18.jpg\n",
      "Processing 20/60: 27.jpg\n",
      "Processing 30/60: 36.jpg\n",
      "Processing 40/60: 45.jpg\n",
      "Processing 50/60: 54.jpg\n",
      "---------------------------------------\n",
      "Took  38.17236852645874 seconds\n",
      "=======================================\n",
      "Dataset: RoadAnomaly\n",
      "Method: MSP (Threshold: 0.5)\n",
      "Per-Class IoU:\n",
      "\u001b[32;1m90.68\u001b[0m Normal/Background\n",
      "\u001b[33;1m22.02\u001b[0m Anomaly\n",
      "=======================================\n",
      "MEAN IoU:  \u001b[34;1m56.35\u001b[0m %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F5D9EF2460>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: f12d2d2c-e77e-49d0-a881-405bb0ee701a)')' thrown while requesting HEAD https://huggingface.co/timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F5D9EF2850>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 376a44dc-9638-40cb-9943-e64642cfbea5)')' thrown while requesting HEAD https://huggingface.co/timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F5D9EF2BE0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: d42376f0-f664-459c-8212-bbfe415eebcd)')' thrown while requesting HEAD https://huggingface.co/timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F5D9EF2F70>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 0f62c8e3-d93d-4c97-aa4c-a2eac78b33e3)')' thrown while requesting HEAD https://huggingface.co/timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F5D9F86340>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 81665f8d-7398-4eba-a128-1b1b8c7a41a2)')' thrown while requesting HEAD https://huggingface.co/timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F5D9F866D0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: fd6800e4-5d59-4e45-aadf-2f68e99e5d91)')' thrown while requesting HEAD https://huggingface.co/timm/vit_base_patch14_reg4_dinov2.lvd142m/resolve/main/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!python eval/eval_iouEoMT.py --input \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\Validation_Dataset\\RoadAnomaly\" --dataset RoadAnomaly --config \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt\\configs\\dinov2\\cityscapes\\semantic\\eomt_base_640.yaml\" --ckpt \"C:\\Users\\karee\\Desktop\\Anomaly-Project\\MaskArchitectureAnomaly_CourseProject\\eomt_checkpoints\\epoch_106-step_19902_eomt.ckpt\" --method MSP --threshold 0.5 --tempScale 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80d545",
   "metadata": {},
   "source": [
    "eval_iouEoMT computes the mIoU and IoU per class (ID or OoD)\n",
    "The code binarizes the outputs of the model in order to adapt to anomaly segmentation requirements. For that purpose a new argument is used '--threshold' which defines the threshold score for the criteria of binarization. The threshold's value is to be tuned for the value that yields best results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
